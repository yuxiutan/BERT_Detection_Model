#!/usr/bin/env python3
"""
é‡è¨“ç·´ç®¡ç†å™¨
è² è²¬è‡ªå‹•åŒ–æ¨¡å‹é‡è¨“ç·´æµç¨‹ï¼ŒåŒ…å«æ¨¡å‹å‚™ä»½ã€ç‰ˆæœ¬ç®¡ç†å’Œè‡ªå‹•åŒ–è¨“ç·´
"""

import os
import json
import shutil
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any
import torch

from Model_API.retrain_model import ModelRetrainer

logger = logging.getLogger(__name__)

class RetrainManager:
    def __init__(self):
        self.model_dir = Path("/app/Model")
        self.backup_dir = Path("/app/model_backups")
        self.low_confidence_file = Path("/app/low_confidence_data/low_confidence_events.json")
        self.data_dir = Path("/app/data")
        
        # æ¨¡å‹æª”æ¡ˆè·¯å¾‘
        self.original_model_path = self.model_dir / "bert_model.pth"
        self.current_model_path = self.model_dir / "bert_model_current.pth"
        
        # å‚™ä»½è¨­å®š
        self.max_backups = int(os.getenv('MODEL_BACKUP_COUNT', '3'))
        
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ¨¡å‹æª”æ¡ˆ
        self._initialize_model_files()
        
        logger.info(f"ğŸ”„ é‡è¨“ç·´ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§å‚™ä»½æ•¸: {self.max_backups}")
    
    def _initialize_model_files(self):
        """åˆå§‹åŒ–æ¨¡å‹æª”æ¡ˆï¼Œç¢ºä¿æœ‰åŸå§‹æ¬Šé‡æª”æ¡ˆ"""
        try:
            # å¦‚æœæ²’æœ‰åŸå§‹æ¨¡å‹æª”æ¡ˆï¼Œå‰µå»ºä¸€å€‹
            if not self.original_model_path.exists():
                logger.warning("âš ï¸ æœªæ‰¾åˆ°åŸå§‹æ¨¡å‹æª”æ¡ˆï¼Œè«‹ç¢ºä¿æ¨¡å‹æª”æ¡ˆå­˜åœ¨")
                return
            
            # å¦‚æœæ²’æœ‰ç•¶å‰æ¨¡å‹æª”æ¡ˆï¼Œå¾åŸå§‹æ¨¡å‹è¤‡è£½
            if not self.current_model_path.exists():
                shutil.copy2(self.original_model_path, self.current_model_path)
                logger.info("ğŸ“‹ å·²å¾åŸå§‹æ¨¡å‹å‰µå»ºç•¶å‰æ¨¡å‹æª”æ¡ˆ")
                
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ¨¡å‹æª”æ¡ˆå¤±æ•—: {str(e)}")
    
    async def retrain_model(self) -> bool:
        """
        åŸ·è¡Œæ¨¡å‹é‡è¨“ç·´æµç¨‹
        
        Returns:
            bool: é‡è¨“ç·´æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("ğŸš€ é–‹å§‹è‡ªå‹•åŒ–æ¨¡å‹é‡è¨“ç·´æµç¨‹...")
            
            # 1. æª¢æŸ¥ä½ä¿¡å¿ƒåº¦è³‡æ–™
            low_confidence_data = self._load_low_confidence_data()
            if not low_confidence_data:
                logger.info("ğŸ“­ æ²’æœ‰ä½ä¿¡å¿ƒåº¦è³‡æ–™ï¼Œè·³éé‡è¨“ç·´")
                return True
            
            logger.info(f"ğŸ“Š æ‰¾åˆ° {len(low_confidence_data)} å€‹ä½ä¿¡å¿ƒåº¦äº‹ä»¶ç”¨æ–¼é‡è¨“ç·´")
            
            # 2. å‚™ä»½ç•¶å‰æ¨¡å‹
            backup_success = self._backup_current_model()
            if not backup_success:
                logger.error("âŒ æ¨¡å‹å‚™ä»½å¤±æ•—ï¼Œä¸­æ­¢é‡è¨“ç·´")
                return False
            
            # 3. æº–å‚™è¨“ç·´è³‡æ–™
            training_data_path = self._prepare_training_data(low_confidence_data)
            if not training_data_path:
                logger.error("âŒ æº–å‚™è¨“ç·´è³‡æ–™å¤±æ•—")
                return False
            
            # 4. åŸ·è¡Œé‡è¨“ç·´
            retrain_success = await self._execute_retrain(training_data_path)
            if not retrain_success:
                logger.error("âŒ é‡è¨“ç·´åŸ·è¡Œå¤±æ•—")
                return False
            
            # 5. é©—è­‰æ–°æ¨¡å‹
            validation_success = self._validate_new_model()
            if not validation_success:
                logger.error("âŒ æ–°æ¨¡å‹é©—è­‰å¤±æ•—ï¼Œæ¢å¾©å‚™ä»½")
                self._restore_from_backup()
                return False
            
            # 6. æ¸…ç†ä½ä¿¡å¿ƒåº¦è³‡æ–™æª”æ¡ˆ
            self._clear_low_confidence_data()
            
            # 7. æ¸…ç†èˆŠå‚™ä»½
            self._cleanup_old_backups()
            
            logger.info("âœ… æ¨¡å‹é‡è¨“ç·´æµç¨‹å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡è¨“ç·´æµç¨‹å¤±æ•—: {str(e)}")
            return False
    
    def _load_low_confidence_data(self) -> List[Dict[str, Any]]:
        """è¼‰å…¥ä½ä¿¡å¿ƒåº¦äº‹ä»¶è³‡æ–™"""
        try:
            if not self.low_confidence_file.exists():
                return []
            
            events = []
            with open(self.low_confidence_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        events.append(json.loads(line))
            
            return events
        except Exception as e:
            logger.error(f"è¼‰å…¥ä½ä¿¡å¿ƒåº¦è³‡æ–™å¤±æ•—: {str(e)}")
            return []
    
    def _backup_current_model(self) -> bool:
        """å‚™ä»½ç•¶å‰æ¨¡å‹"""
        try:
            if not self.current_model_path.exists():
                logger.warning("âš ï¸ ç•¶å‰æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œç„¡æ³•å‚™ä»½")
                return False
            
            # ç”Ÿæˆå‚™ä»½æª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³ï¼‰
            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            backup_filename = f"bert_model_backup_{timestamp}.pth"
            backup_path = self.backup_dir / backup_filename
            
            # åŸ·è¡Œå‚™ä»½
            shutil.copy2(self.current_model_path, backup_path)
            logger.info(f"ğŸ’¾ æ¨¡å‹å·²å‚™ä»½è‡³: {backup_filename}")
            
            return True
            
        except Exception as e:
            logger.error(f"æ¨¡å‹å‚™ä»½å¤±æ•—: {str(e)}")
            return False
    
    def _prepare_training_data(self, low_confidence_events: List[Dict[str, Any]]) -> str:
        """æº–å‚™é‡è¨“ç·´è³‡æ–™"""
        try:
            # å‰µå»ºè¨“ç·´è³‡æ–™æª”æ¡ˆ
            timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
            training_file = self.data_dir / f"retrain_data_{timestamp}.json"
            
            # è½‰æ›è³‡æ–™æ ¼å¼ä¾›è¨“ç·´ä½¿ç”¨
            training_data = []
            for event in low_confidence_events:
                training_sample = {
                    "text": event.get("log_data", ""),
                    "label": 1,  # å‡è¨­ä½ä¿¡å¿ƒåº¦äº‹ä»¶éœ€è¦é‡æ–°æ¨™è¨˜ç‚ºæ”»æ“Š
                    "timestamp": event.get("timestamp"),
                    "confidence": event.get("confidence", 0.0),
                    "agent_name": event.get("agent_name"),
                    "rule_id": event.get("rule_id")
                }
                training_data.append(training_sample)
            
            # å¯«å…¥æª”æ¡ˆ
            with open(training_file, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“ å·²æº–å‚™ {len(training_data)} ç­†é‡è¨“ç·´è³‡æ–™: {training_file.name}")
            return str(training_file)
            
        except Exception as e:
            logger.error(f"æº–å‚™è¨“ç·´è³‡æ–™å¤±æ•—: {str(e)}")
            return None
    
    async def _execute_retrain(self, training_data_path: str) -> bool:
        """åŸ·è¡Œæ¨¡å‹é‡è¨“ç·´"""
        try:
            logger.info("ğŸ”¥ é–‹å§‹åŸ·è¡Œæ¨¡å‹é‡è¨“ç·´...")
            
            # åˆå§‹åŒ–é‡è¨“ç·´å™¨
            retrainer = ModelRetrainer(
                model_path=str(self.current_model_path),
                training_data_path=training_data_path,
                output_path=str(self.current_model_path)
            )
            
            # åŸ·è¡Œé‡è¨“ç·´ï¼ˆé€™è£¡æ‡‰è©²æ˜¯ç•°æ­¥çš„ï¼‰
            success = await retrainer.retrain()
            
            if success:
                logger.info("âœ… æ¨¡å‹é‡è¨“ç·´å®Œæˆ")
                return True
            else:
                logger.error("âŒ æ¨¡å‹é‡è¨“ç·´å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"åŸ·è¡Œé‡è¨“ç·´å¤±æ•—: {str(e)}")
            return False
    
    def _validate_new_model(self) -> bool:
        """é©—è­‰æ–°è¨“ç·´çš„æ¨¡å‹"""
        try:
            logger.info("ğŸ” é©—è­‰æ–°è¨“ç·´çš„æ¨¡å‹...")
            
            # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”å¯è¼‰å…¥
            if not self.current_model_path.exists():
                logger.error("æ–°æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨")
                return False
            
            # å˜—è©¦è¼‰å…¥æ¨¡å‹
            try:
                model_state = torch.load(self.current_model_path, map_location='cpu')
                logger.info("âœ… æ–°æ¨¡å‹æª”æ¡ˆé©—è­‰æˆåŠŸ")
                return True
            except Exception as e:
                logger.error(f"æ–°æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
                return False
                
        except Exception as e:
            logger.error(f"æ¨¡å‹é©—è­‰å¤±æ•—: {str(e)}")
            return False
    
    def _restore_from_backup(self) -> bool:
        """å¾æœ€æ–°å‚™ä»½æ¢å¾©æ¨¡å‹"""
        try:
            logger.info("ğŸ”„ æ­£åœ¨å¾å‚™ä»½æ¢å¾©æ¨¡å‹...")
            
            # æ‰¾åˆ°æœ€æ–°çš„å‚™ä»½æª”æ¡ˆ
            backup_files = list(self.backup_dir.glob("bert_model_backup_*.pth"))
            if not backup_files:
                logger.error("æ²’æœ‰æ‰¾åˆ°å‚™ä»½æª”æ¡ˆ")
                return False
            
            # æŒ‰æª”åæ’åºï¼Œå–æœ€æ–°çš„
            latest_backup = sorted(backup_files)[-1]
            
            # æ¢å¾©å‚™ä»½
            shutil.copy2(latest_backup, self.current_model_path)
            logger.info(f"âœ… å·²å¾å‚™ä»½æ¢å¾©: {latest_backup.name}")
            
            return True
            
        except Exception as e:
            logger.error(f"å¾å‚™ä»½æ¢å¾©å¤±æ•—: {str(e)}")
            return False
    
    def _clear_low_confidence_data(self):
        """æ¸…ç©ºä½ä¿¡å¿ƒåº¦äº‹ä»¶è³‡æ–™æª”æ¡ˆ"""
        try:
            if self.low_confidence_file.exists():
                # å‚™ä»½èˆŠè³‡æ–™
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
                backup_file = self.low_confidence_file.parent / f"processed_low_confidence_{timestamp}.json"
                shutil.move(self.low_confidence_file, backup_file)
                logger.info(f"ğŸ“¦ ä½ä¿¡å¿ƒåº¦è³‡æ–™å·²å‚™ä»½è‡³: {backup_file.name}")
            
            # å‰µå»ºæ–°çš„ç©ºæª”æ¡ˆ
            self.low_confidence_file.touch()
            
        except Exception as e:
            logger.error(f"æ¸…ç†ä½ä¿¡å¿ƒåº¦è³‡æ–™å¤±æ•—: {str(e)}")
    
    def _cleanup_old_backups(self):
        """æ¸…ç†éèˆŠçš„æ¨¡å‹å‚™ä»½ï¼Œåªä¿ç•™æœ€æ–°çš„ N å€‹"""
        try:
            backup_files = list(self.backup_dir.glob("bert_model_backup_*.pth"))
            
            if len(backup_files) <= self.max_backups:
                return
            
            # æŒ‰æª”åæ’åºï¼ˆåŒ…å«æ™‚é–“æˆ³ï¼‰
            backup_files.sort()
            
            # åˆªé™¤å¤šé¤˜çš„èˆŠå‚™ä»½
            files_to_delete = backup_files[:-self.max_backups]
            
            for file_path in files_to_delete:
                file_path.unlink()
                logger.info(f"ğŸ—‘ï¸ å·²åˆªé™¤èˆŠå‚™ä»½: {file_path.name}")
            
            logger.info(f"âœ… å‚™ä»½æ¸…ç†å®Œæˆï¼Œä¿ç•™æœ€æ–° {self.max_backups} å€‹å‚™ä»½")
            
        except Exception as e:
            logger.error(f"æ¸…ç†å‚™ä»½å¤±æ•—: {str(e)}")
    
    def get_current_model_version(self) -> str:
        """ç²å–ç•¶å‰æ¨¡å‹ç‰ˆæœ¬è³‡è¨Š"""
        try:
            if self.current_model_path.exists():
                mtime = self.current_model_path.stat().st_mtime
                return datetime.fromtimestamp(mtime, tz=timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
            else:
                return "æœªçŸ¥"
        except Exception as e:
            logger.error(f"ç²å–æ¨¡å‹ç‰ˆæœ¬å¤±æ•—: {str(e)}")
            return "éŒ¯èª¤"
    
    def get_backup_list(self) -> List[Dict[str, Any]]:
        """ç²å–å‚™ä»½æ¨¡å‹åˆ—è¡¨"""
        try:
            backup_files = list(self.backup_dir.glob("bert_model_backup_*.pth"))
            backup_files.sort(reverse=True)  # æœ€æ–°çš„åœ¨å‰
            
            backups = []
            for backup_file in backup_files:
                stat = backup_file.stat()
                backups.append({
                    "filename": backup_file.name,
                    "size_mb": round(stat.st_size / (1024 * 1024), 2),
                    "created_time": datetime.fromtimestamp(stat.st_ctime, tz=timezone.utc).isoformat(),
                    "modified_time": datetime.fromtimestamp(stat.st_mtime, tz=timezone.utc).isoformat()
                })
            
            return backups
            
        except Exception as e:
            logger.error(f"ç²å–å‚™ä»½åˆ—è¡¨å¤±æ•—: {str(e)}")
            return []
    
    def restore_from_backup(self, backup_filename: str) -> bool:
        """å¾æŒ‡å®šå‚™ä»½æ¢å¾©æ¨¡å‹"""
        try:
            backup_path = self.backup_dir / backup_filename
            
            if not backup_path.exists():
                logger.error(f"å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: {backup_filename}")
                return False
            
            # å…ˆå‚™ä»½ç•¶å‰æ¨¡å‹
            current_backup_success = self._backup_current_model()
            if not current_backup_success:
                logger.warning("âš ï¸ ç•¶å‰æ¨¡å‹å‚™ä»½å¤±æ•—ï¼Œä½†ç¹¼çºŒæ¢å¾©æ“ä½œ")
            
            # æ¢å¾©æŒ‡å®šå‚™ä»½
            shutil.copy2(backup_path, self.current_model_path)
            logger.info(f"âœ… å·²å¾å‚™ä»½æ¢å¾©æ¨¡å‹: {backup_filename}")
            
            return True
            
        except Exception as e:
            logger.error(f"å¾å‚™ä»½æ¢å¾©å¤±æ•—: {str(e)}")
            return False
